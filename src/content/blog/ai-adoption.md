---
title: The AI Conundrum
description: AI is everywhere, but is that a good thing?
pubDate: Dec 4 2025
heroImage: "@blog/ai-blog.jpg"
category: Site News
tags:
  - observation
  - AI
  - Technology
showImage: true
showVideo: false
YT: No
alt: "A picture of falling text reminiscent of the terminator movies, with a blurry person in the foreground. It's not really related to the article below, it's just a way to fill space for visual appeal. It looks cool and techy."
author: Sam
---

Get out your torches and pitchforks, I'm going to talk about AI and I think we all know how contentious a topic THAT can be. There are suporters who see it as the best thing since sliced bread and detractors who consider it the first sign of the pending apocalypse. I'm not going to look at is AI a good thing or a bad thing. I'm going to look at the logistics, some impacts on work, and ask the question: is now the time for AI?

I'm going to focus on OpenAI for this. There are others in the industry, but they all ultimately face the same problems.

# Assessing the AI Future

OpenAI was founded around 2015. Chat GPT came out in 2022. AI image generators came out in the same time frame. In 2024 and 2025 AI Video Generation started to become a big thing. Shortly after these releases a wide variety of products began adding AI to their branding and building out AI features. There were tools that had free tiers and tools that had paid offerings giving more access. Various academic institutions had to deal with AI as a means of cheating. Workplaces started demanding AI-Savy workers. Somewhere in all of this frenzy to use and buildout a new technology the numbers got ludicrously massive, with trillion-dollar figures being thrown around for building out AI services.

In the midst of the AI adoption there have been issues, news stories of AI fabricating legal precedents in court cases and lawsuits driven by copyright laws. Actual research and proof about AI's success, real, concrete numbers that prove its value have been slower to come. People using AI say it makes them faster, but that's subjective. Getting the full picture needs some qualitative work to assess whether AI delviers a strong value for its cost and to see how it effects the actual workforce. There is where things will start to hit some problems.

## Significant Financial Needs

First and foremost, the companies making AI tech are spending money. Every prompt has a calculable, knowable cost to that service provider. The cost of electricity, water, and network resources to fulfill the request, plus some measure of the R&D costs, plus the cost to build the data center, plus some markup for actual profit. Outside the AI companies, we can't know what these costs are for sure. Trying to calculate them is something for bigger news sites than just one small dev who's following the news. 

We do have some public statments from OpenAI about their costs. As reported by Fortune and Bloomberg, [open AI loses money when they charge $200 per month](https://fortune.com/2025/01/07/sam-altman-openai-chatgpt-pro-subscription-losing-money-tech/). Reporting in CNBC says that [OpenAI is making $20 billion this year](https://www.cnbc.com/2025/11/06/sam-altman-says-openai-will-top-20-billion-annual-revenue-this-year.html). That's a lot of money, and all of it is still an operating lost. This poses a logistical problem.

For OpenAI as a business to continue operating, at some point their revenue needs to exceed their costs. OpenAI's financial backers will expect an ROI, Return On Investment. This company can't operate as a public charity, especially after converting from a non-profit to a for-profit entity. The cost to use OpenAI will have to increase. If the cheap plan is $20, and $200 doesn't break even, that paints a picture that these services need a drastic price increase. As the prices increase, it makes AI harder to justify. The average consumer might tolerate $20 to have a little assistant helping them, but they won't stomach $200/month. Companies seeking to replace their workforce might stomach $200 or $2000 per worker they replace, but maybe not $20,000.

At some point, AI providers won't be able to generate any more money on a per-customer basis. [OpenAI integrating ads](https://www.fastcompany.com/91452882/openai-ads-chatgpt-google-gemini) into their services would be a way to increase revenue without trying to squeeze money directly from their customers. Advertising is an enormous business all over the world and it can drive some enormous revenues. [In the US alone](https://www.byyd.me/en/blog/2025/03/us-advertising-market-trends/) ad spending is over $426 Billion annually. If OpenAI gets a cut of that pie, it could add billions to their bottom line.

That's money OpenAI will need, they've committed to [spending $1.4 Trillion](https://techcrunch.com/2025/11/06/sam-altman-says-openai-has-20b-arr-and-about-1-4-trillion-in-data-center-commitments/) in building out datacenters over the next decade.

### Interest and Debt

OpenAI's big build out will require more money than they're pulling in revenue. This means either raising additional capital or getting financiers to give them a loan. If OpenAI's revenue stays constant and if all of that revenue is put against the debt, and if there is no interst on the debt, that would take 70 years to pay off. On a 50 year loan with 6% interest, that's $7.37 billion dollars in payments every month, for a yearly total of $88.4 billion. Just to service the debt, they need to grow their revenue by over 4 times. To service the debt and keep their current financial situation that's over 5 times growth. It might take a 7, 8, or 9x their current revenues to service that debt and start providing some ROI for the investors.

There are companies that have hundreds of billions in revenue, so that isn't insurmountable. Most of them don't have trillion dollar debts. A company like [Walmart pulls in around $700 billion](https://companiesmarketcap.com/walmart/revenue/) in revenue and around $30 billion in profit. [Amazon](https://companiesmarketcap.com/amazon/earnings/) pulls similar revenues and could come away with $100 billion. Numbers this big do happen in the business world, but do they happen for this business model? Walmart sells products so most of its costs are buying products, paying workers, and maintaining its buildings - substantially less than OpenAI's $1.4 trillion. Amazon is mostly an eCommerce giant, but they do have AWS and data centers. AWS also has an enormous customer base building on that platform, which they've steadily grown over the past two decades.

### Market Adoption

This brings us to the problem of actual adoption. AI tech is billed as a revolution that will fundementally shift the entirety of humanity. This is a tectonic shift that will utterly reshape the foundations of our lives. Nothing will be the same ever again. It is a stark before/after moment bigger than electricity, the car, and sliced bread put together. At least, that's the way it's billed, but I don't see that type of adoption. Recent history gives us a similar technology that we can measure against: cell phones.

In the year 2006 the most advanced, business-valable cell phone was a Blackberry, sold by Research In Motion. It was a little square phone with a physical keyboard, no touch screen, and a little trackball used to scroll around. If you were an average consumer and you had a cool phone, you might've spent $100 on a Motorola Razor - a thin flip phone. Your average phone in that era was for making calls. It might've done web browsing but it wasn't a great experience. Texting was a thing, but it was a slow and irksome process to type out a text message on a 10 digit keypad. Companies like Boost Mobile had a walkie-talkie-like push to talk feature that worked better than texting. Customers paid by the text or by the minute unless they had a nicer phone plan.

In 2007 the iPhone launched. The app store followed. Android released. The entire world changed in just a few years. My parents bought their first smart phones. My friends had smart phones. Apps for everything came out. For a time a stupid light saber app that made swooshing sounds was the most popular and coolest thing on a phone. It was like the whole world got hooked on a drug: the smart phone. It obliterated sales of video and digital cameras, MP3 players, and more. A dozen single-purpose devices just went extinct because we didn't need them. Everyone had a phone and that phone did everything.

Dozens of companies got in the industry. Samsung, LG, HTC, Asus, Motorola, Google, Amazon, and more. Tablets absolutely exploded. Everyone had a smartphone and a lot of people had tablets. The Nintendo Switch came out to create the first "Gaming Tablet" with mass-market appeal. This tech absolutely kicks up trillions of dollars in money moving around every year. Consumers pay $1000+ for a good smartphone. Sometimes yearly, sometimes every few years. There's spending on apps, games, subscriptions, and more all tied to the phone.

**AI  hasn't been like that.**

My parents, sister, cousins, and more don't know what AI is. They don't see a reason to spend money on it. They want to turn on their TV and watch Netflix. They want to look up when a local restaurant's closing. These are normal people and tothem, AI is the same tier of novelty as Siri. It's this cute little thing that can answer your questions. I know friends who absolutely hate AI and I know ones who think it has niche uses. I know a handful of die-hard "AI is the next revolution!" friends, but I don't know if even they are willing to pay enough to make OpenAI and others solvent.

We've been here before. Google, Apple, Samsung, and others were all fast to jump in on smart speakers and voice assistants that never found a path to profitability despite widespread deployment. The common-user's AI experience is I think very similar to the smart speaker.

The billions OpenAI (let alone the other providers) needs in revenue won't come from the consumer market.

### Corporate Adoption

Companies have been integrating and adopting AI everywhere they can. You can't turn on your TV without seeing an ad for AI this or that. AI powered Ovens, AI power assistant, our new app uses AI to run your business, do your taxes, walk your dog, and change your tires. Every big company is doing the thing big-companies do: chasing the band wagon. If you can find anyway to tie your product to AI, you'll throw it out there. To business executives it sounds hip, it's the future, we all need to be on the cutting edge of buzzwords.

That begs the question: does AI have a place in every use-case?

HR systems are getting AI. Coding systems are getting AI. AI is in your office suite. It's in your design tools. It's in the phone system. It's replacing tech support so companies can lay off skilled workers and replace them with a little bot. The business case is that these will of course pay themselves off because they'll save money on unnecessary woorkers or speed up the process. Does that pan out when we gather data?

A plethora of news reports and studies spell out the challenges in AI Adoption:

- [Harvard Business Review - 'Workslop is Destroying Productivity'](https://hbr.org/2025/09/ai-generated-workslop-is-destroying-productivity)
- [METR - AI Impact on Open-Source Devs](https://metr.org/blog/2025-07-10-early-2025-ai-experienced-os-dev-study/)
- [MIT - 95% of AI Pilots Failing](https://fortune.com/2025/08/18/mit-report-95-percent-generative-ai-pilots-at-companies-failing-cfo/)

There are other articles that make a case for AI being doomed. I think what this makes a case for is that AI was adopted too quickly. I think this also makes a case that major companies adopting AI will not provide enough revenue to save OpenAI. Some AI companies will definitely come through this and still be AI companies on the other side, but I think the market will end up with less AI than it has now.

## The Worker Factor

At a human, personal level, we have another factor in the adoption of AI: how it effects us long-term. [Time reports that AI use has an effect on the brain](https://time.com/7295195/ai-chatgpt-google-learning-school/). It's a negative effect according to research by MIT. Other studies explore similar lines of thoughts: does AI change the way we think and how we function? There have been similar results, [doctors can lose their skills](https://www.npr.org/sections/shots-health-news/2025/08/19/nx-s1-5506292/doctors-ai-artificial-intelligence-dependent-colonoscopy) from relying on AI and [that's to be expected](https://www.cigionline.org/articles/the-silent-erosion-how-ais-helping-hand-weakens-our-mental-grip/). 

Our brains get rid of neural connections we don't use.

When I was in 5th grade, we did multiplication drills. We had 15 minutes to answer as many problems on a paper as possible. There might've been 50 or 100 problems. They were usually 1-step multiplication and division. The first few times doing those drills I didn't get the full page. Give it a few weeks and I was memorizing pieces of the answers. I new 8x7 = 56 as a simple fact. 9x9=81. These were coded in my brain like shortcuts and I had a hundred of them. Repeition and experience drove that information in and it stayed. Pieces of it linger. I would still be screwed performing those tests today. It's been too long and my math is rusty. I learned the various math-concepts and those remain rock-solid (please don't ask me to do a derivative). The real-time calculation skills were replaced by my physical calculator. Those skills weren't needed.

Workers who rely on AI will lose skills. You'll become a worse coder, have less knowledge of your codebase, produce more bugs, and have a worse product. It is possible you'll output more code or ship faster, but there will be a cost. In some places, building fast in-house prototypes that trade off may be acceptable. In producing production code however, I think it has some challenges to reliably getting the job done.

# How Should We Use AI?

The world responded to AI by putting it everywhere. Companies saw it as a way to save money or increase productivity. Management believed it could just be dropped in with  zero consideration and instantly change the game. Marketers believed it was a key piece of selling their products because it was buzzy and essential. As some of the studies bear out: AI can have a place, but that place needs to be carefully considered. Instead of cramming in a new technology, it should be built up with purpose and intent. In places where AI is smartly integrated, with care and thought, it does bring a tangible benefit. That process requires companies to put on the breaks, test, research, and then implement AI features in a controlled and reasonable fashion.

I have used AI in my job hunting. The job hunter's dilema has been the ATS. Application Tracking System. At least that's the common belief and I do believe my own experiences align with that. I use an app that customizes my resume per-job application. I don't let it do the work for me. The app suggests edits and then I'm free to accept, edit, or reject them. I'm able to get ideas that might score better on ATS grading systems and put them to work in ways that don't lie. I'm still writing and thinking my way through every application and my skills won't degrade because ofthat usage. The same system generates cover letters and sometimes I use them with heavy edits, sometimes I discard them altogether to write it by hand. Other candidates wholesale let AI write their resume, cover letter, and autonomously apply to jobs. It would feel nice to let a machine do the work, but as some businesses I think are discovering: that doesn't drive results.

My general, personal stance is to use AI slowly in my own workflows, where it makes sense. If an employer mandates AI in the office, I'm onboard to use it, they're paying for it. I have my reservations, but it's still the boss's company to run. In my free time, I'll still be a 1005 human-creator.

## The Cost of Adoption

With all of that said, there is one closing issue to consider:

What is the cost of early adoption?

All of these companies have created their own AI or written scripts that hook into OpenAI, Gemini, or whatever other systems are out there. Millions of hours of work have been put into building out all of this tooling. What does it do to your balance sheets when those tools end up being worthless? What do you do if the AI companies collapse from the hypothetical AI Bubble?

There is a Silicon Valley ethos to move fast and break things. We've all watched the industries move with incredible speed. Now, we sit and watch to see what breaks when a little quake shakes the house of cards. That could be disasterous economically, but it's also where the numbers seem to point.

At the end of the day, I could be wrong too. The businesses rushing in could see record profits for the next century. My caution could put me a little behind the pack or it could preserve my skills by never forming dependence on a short-lived technology.

## The Future of AI

Despite my general caution and focus on the negative aspects of the AI business, I do think at-large the technology will survive. GPT AIs were first used to power translation software and AI will absolutely persist in that field. AI transcription technology will survive. The base technologies will survive. The ways we interact with them, the companies providing those services, and the ways we use them, that is the real mystery.